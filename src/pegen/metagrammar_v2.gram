@header """\
from ast import literal_eval
from typing import List, Union
import token
import tokenize
from tokenize import TokenInfo

from pegen.grammar import (
    Alt,
    Action,
    GrammarItem,
    Cut,
    ExternDecl,
    Forced,
    Gather,
    Group,
    Item,
    Lookahead,
    LookaheadOrCut,
    MetaTuple,
    NameLeaf,
    TopLevelItem,
    NegativeLookahead,
    Opt,
    Plain,
    PositiveLookahead,
    Repeat0,
    Repeat1,
    Rhs,
    Rule,
    RuleName,
    Grammar,
    StringLeaf,
)

#TODO: Blocks (having its own return) vs. expressions
def _normalize_linecol(tokens: List[TokenInfo]) -> List[TokenInfo]:
    assert tokens
    # first token has line 1
    first_line = tokens[0].start[0]
    line_subtract = tokens[0].start[0] - 1
    column_subtract = tokens[0].start[1] - 1
    # TODO: column
    for token in tokens:
        if token.line != first_line:
            ...
    return [token._replace(start=(token.start[0] - line_subtract, token.start[1]),
                           end=(token.end[0] - line_subtract, token.end[1]))
            for token in tokens]


class Base(DefaultParser):
    @memoize
    def action_contents(self) -> Optional[Action]:
        m = self.mark()
        level = 1
        tokens = []
        prevmark = m
        while True:
            t = self._tokenizer.peek()
            if t.type == token.ENDMARKER:
                self.reset(m)
                return None
            self._tokenizer.getnext()
            if t.string == "}":
                level -= 1
                if level == 0:
                    break
            tokens.append(t)
            if t.string == "{":
                level += 1
            prevmark = self.mark()
        self.reset(prevmark) # Don't consume the last right brace
        tokens = _normalize_linecol(tokens)
        #print(tokens)
        #print(tokenize.untokenize(tokens))
        return tokenize.untokenize(tokens)
"""

@base Base

start[Grammar]: grammar $

grammar[Grammar]:
    metas=metas? rules extern_rules=extern_rules? { Grammar(rules, extern_rules or [], metas or []) }

metas[List[MetaTuple]]:
    | meta metas { [meta] + metas }
    | meta { [meta] }

meta[MetaTuple]:
    | "@" NAME NEWLINE { (name.string, None) }
    | "@" a=NAME b=NAME NEWLINE { (a.string, b.string) }
    | "@" NAME STRING NEWLINE { (name.string, literal_eval(string.string)) }

rules[List[Rule]]:
    | rule rules { [rule] + rules }
    | rule { [rule] }

rule[Rule]:
    rulename opt=memoflag? ":" rule_rhs { Rule(rulename[0], rulename[1], rule_rhs, memo=opt) }

# TODO: "nullable" / "not nullable" mark? (which?) (for first_sets.py)
extern_rules[List[ExternDecl]]:
    | extern_rule extern_rules { [extern_rule] + extern_rules }
    | extern_rule { [extern_rule] }

extern_rule[ExternDecl]:
    "extern" NAME ann=annotation? NEWLINE { ExternDecl(name.string, ann) }

rulename[RuleName]:
    | NAME annotation { (name.string, annotation) }
    | NAME { (name.string, None) }
    #| NAME annotation=annotation? { (name.string, annotation) } #XXX: ?

rule_rhs[Rhs]:
    | alts=alts? NEWLINE INDENT more_alts DEDENT { Rhs(alts.alts + more_alts.alts) if alts else more_alts }
    | NEWLINE INDENT alt NEWLINE DEDENT { Rhs([alt]) }
    | alts NEWLINE { alts }

# In the future this may return something more complicated
memoflag[str]:
    '(' "memo" ')' { "memo" }

alts[Rhs]:
    | alt "|" alts { Rhs([alt] + alts.alts) }
    | alt { Rhs([alt]) }

more_alts[Rhs]:
    | "|" alts NEWLINE more_alts { Rhs(alts.alts + more_alts.alts) }
    | "|" alts NEWLINE { Rhs(alts.alts) }

alt[Alt]:
    | items '$' action { Alt(items + [TopLevelItem(None, NameLeaf('ENDMARKER'))], action=action) }
    | items '$' { Alt(items + [TopLevelItem(None, NameLeaf('ENDMARKER'))], action=None) }
    | items action { Alt(items, action=action) }
    | items { Alt(items, action=None) }
    | '$' { Alt([], action=None) }
    #| items e='$'? action=action? {
    #    Alt(items + [TopLevelItem(None, NameLeaf('ENDMARKER'))] if e else items, action=action) }

items[List[TopLevelItem]]:
    | top_level_item items { [top_level_item] + items }
    | top_level_item { [top_level_item] }

# Possibly named item (possibly with a type when named)
top_level_item[TopLevelItem]:
    | NAME annotation '=' ~ item {TopLevelItem(name.string, item, annotation)}
    | NAME '=' ~ item {TopLevelItem(name.string, item)}
    | item {TopLevelItem(None, item)}
    | it=top_level_others {TopLevelItem(None, it)}

top_level_others[LookaheadOrCut]:
    | '&''&' ~ atom {Forced(atom)}
    | '&' ~ atom {PositiveLookahead(atom)}
    | '!' ~ atom {NegativeLookahead(atom)}
    | '~' {Cut()}

item[Item]:
    | '[' ~ alts ']' {Opt(alts)}
    | atom '?' {Opt(atom)}
    | atom '*' {Repeat0(atom)}
    | atom '+' {Repeat1(atom)}
    | sep=atom '.' node=atom '+' {Gather(sep, node)}
    | atom {atom}

atom[Plain]:
    | '(' ~ alts ')' {Group(alts)}
    | NAME {NameLeaf(name.string) }
    | STRING {StringLeaf(string.string)}

# Mini-grammar for the actions and annotations

#action[str]: "{" ~ target_atoms "}" { target_atoms }
action[Action]: "{" ~ action_contents "}" { action_contents }
annotation[str]: "[" ~ target_atoms "]" { target_atoms }
#annotation[str]: "[" ~ text("]") "]" { target_atoms }
#annotation[str]: "->" ~ target_atoms !":" { target_atoms }

target_atoms[str]:
    | target_atom target_atoms { target_atom + " " + target_atoms }
    | target_atom { target_atom }

target_atom[str]:
    | "{" ~ atoms=target_atoms? "}" { "{" + (atoms or "") + "}" }
    | "[" ~ atoms=target_atoms? "]" { "[" + (atoms or "") + "]" }
    | NAME "*" { name.string + "*" }
    | NAME { name.string }
    | NUMBER { number.string }
    | STRING { string.string }
    | l=FSTRING_START m=target_fstring_middle* r=FSTRING_END { l.string + "".join(m) + r.string }
    | "?" { "?" }
    | ":" { ":" }
    | !"}" !"]" OP { op.string }

target_fstring_middle[str]:
    | FSTRING_MIDDLE { fstring_middle.string }
    | "{" { "{" }
    | "}" { "}" }
    | target_atom { target_atom }

#annotation[str]: "[" ~ target_atoms "]" { target_atoms }
extern action_contents[Action]